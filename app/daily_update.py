# update_weather_data.py

import os
import pandas as pd
from datetime import datetime, timedelta
from fetch_data import fetch_weather, get_coordinates
import requests


def fetch_forecast_j_minus_1(city: str) -> pd.DataFrame:
    """
    R√©cup√®re la m√©t√©o de J-1 depuis l‚ÄôAPI forecast (limit√©e √† 7 jours).
    """
    latitude, longitude = get_coordinates(city)
    today = datetime.utcnow().date()
    j_minus_1 = today - timedelta(days=1)

    daily_vars = [
        "temperature_2m_max", "temperature_2m_min", "precipitation_sum",
        "rain_sum", "showers_sum", "snowfall_sum", "windspeed_10m_max",
        "windgusts_10m_max", "sunshine_duration", "uv_index_max",
        "shortwave_radiation_sum", "et0_fao_evapotranspiration", "weathercode"
    ]

    url = (
        f"https://api.open-meteo.com/v1/forecast?"
        f"latitude={latitude}&longitude={longitude}"
        f"&daily={','.join(daily_vars)}"
        f"&forecast_days=7"
        f"&timezone=auto"
    )

    response = requests.get(url)
    data = response.json()

    if "daily" not in data:
        raise ValueError("Pas de donn√©es forecast disponibles.")

    df = pd.DataFrame(data["daily"])
    df["city"] = city
    df["time"] = pd.to_datetime(df["time"])
    df = df[df["time"].dt.date == j_minus_1]

    return df


def update_weather_data(city: str, min_days_missing: int = 1) -> pd.DataFrame:
    safe_city = city.lower().replace(" ", "_")
    file_path = f"data/_{safe_city}_all.csv"

    today = datetime.utcnow().date()
    j_minus_1 = today - timedelta(days=1)
    archive_cutoff = today - timedelta(days=5)

    # Lire fichier existant
    if os.path.exists(file_path):
        df_existing = pd.read_csv(file_path)
        df_existing["time"] = pd.to_datetime(df_existing["time"])
    else:
        df_existing = pd.DataFrame()

    df_combined = df_existing.copy()

    # √âtape 1 : compl√©ter avec archive jusqu‚Äô√† J‚àí5
    if df_existing.empty or df_existing["time"].max().date() < archive_cutoff:
        days_missing = (archive_cutoff - df_existing["time"].max().date()).days if not df_existing.empty else 730
        if days_missing >= min_days_missing:
            print(f"üì¶ Archive: {city} ‚Üí {days_missing} jours manquants...")
            df_archive = fetch_weather(city, past_days=days_missing, use_cache=False)
            df_archive["time"] = pd.to_datetime(df_archive["time"])
            df_combined = pd.concat([df_combined, df_archive], ignore_index=True)

    # √âtape 2 : ajouter J‚àí1 si manquant
    if j_minus_1 not in df_combined["time"].dt.date.values:
        try:
            df_forecast = fetch_forecast_j_minus_1(city)
            if not df_forecast.empty:
                print(f"üîÆ Forecast: {city} ‚Üí ajout de J‚àí1 ({j_minus_1})")
                df_combined = pd.concat([df_combined, df_forecast], ignore_index=True)
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible de r√©cup√©rer J‚àí1 pour {city} : {e}")

    if df_combined.empty:
        print(f"Rien √† mettre √† jour pour {city}")
        return df_combined

    # Nettoyage final
    df_combined = df_combined.drop_duplicates("time").sort_values("time")
    os.makedirs("data", exist_ok=True)
    df_combined.to_csv(file_path, index=False)
    print(f"‚úÖ Donn√©es mises √† jour dans {file_path}")

    return df_combined


if __name__ == "__main__":
    SWISS_CITIES = [
        "Gen√®ve", "Lausanne", "Zurich", "Berne", "B√¢le",
        "Neuch√¢tel", "Fribourg", "Lugano", "Lucerne", "Sion"
    ]

    # ----- PIPELINE QUOTIDIEN -----
    for city in cities:
        try:
            print(f"üåç Traitement de {city}...")

            # Mise √† jour des donn√©es
            update_weather_data(city)

            # Pr√©diction pour aujourd'hui (J)
            predict_city(city, day_offset=0)

            # Pr√©diction pour demain (J+1)
            predict_city(city, day_offset=1)

        except Exception as e:
            print(f"‚ùå Erreur lors du traitement de {city} : {e}")
